# uq kernel miniapp

A kernel for uncertainty quantification (UQ) codes at NASA.

# Getting Started

1) Clone or download this repository
* It is best to work with and modify the source code using Git ([install/update Git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git)). Using Git, clone the repository to your computer using `git clone https://github.com/nasa/UQ-Kernel-Mini-App.git`. Otherwise, the repository can be downloaded manually with the "Clone or download" button above. 
2) Add the repository to your Python path
* On Mac/Linux, add `export PYTHONPATH=$PYTHONPATH:Path/To/Your/Repo/` to your ~/.bashrc file (click [here](https://stackoverflow.com/questions/3402168/permanently-add-a-directory-to-pythonpath) for more details). For Windows, see this [link](https://stackoverflow.com/questions/3701646/how-to-add-to-the-pythonpath-in-windows-so-it-finds-my-modules-packages). This makes it possible to run the code in this repository from anywhere on your computer.
3) Make sure you have the required Python modules
* The repository uses a few external Python modules (currently just `numpy` and `scipy`). Either install them manually, or using pip: `pip install -r requirements.txt` or Anaconda: `conda install --yes --file requirements.txt` from the top directory of the repository.
4) Test that everything is working correctly
* Navigate to the `tests/` directory in the repository and type `python engine_check.py`. If things are working as expected, you should see an output similar to:
```
Engine Check Results:
  Output is Correct!
  Theoretical execution time was 9.40658189601207
  Actual execution time was 9.961344003677368
  Efficiency was 0.9443
```

# VT Capstone project

## Challenge
Devise  an  interface  (front end)  and  computational  engine  (back end)  
that  increases  the  usability, efficiency, and scalability of NASA 
open-source uncertainty quantification software.

### Sub-challenge 1: interface
 How can we best allow users from all disciplines to “plug” their own 
 computational model into our Python-based UQ software?

#### Examples of possible types of models
 * Model implemented entirely/explicitly with Python code
 ```python
def evaluate(self, inputs):
	<a bunch of python code to calculate output>
	return output
```
 * Model is a Python wrapper that calls a simulation executable
```python
def evaluate(self, inputs):
	self.write_input_file_to_disc(inputs)
	self.execute_model()
	output = self.parse_output_file()
	return output
```
 * Model created from input/output dataset – initialized from dataset;  
 evaluate() function finds and returns output for given input
 * Model loads a previously-trained machine learning model from file (a Python 
 pickle file) and uses it to make a prediction in evaluate()
 
### Implementation
A starting interface for a `UQModel` is defined in `uq_kernel/model.py`.  It 
illustrates the parts of a model that must be exposed to the UQ framework. 
Defining implementations of this interface to account for different possible 
models is one option to pursue this challenge.  Alternative solutions are 
encouraged as well.  Everything, including the basic interface in 
`uq_kernel/model.py` can be modified to suit the chosen approach.

### Sub-challenge 2: engine
**A load balancing issue for parallel computing:** How can we devise a strategy 
to execute a set of computational models with *varying run times* an arbitrary 
number of times each in an efficient and scalable manner.

#### Problem Definition
**Given**
 * A set of Python models (like the ones developed in sub-challenge 1)
 * The estimated cost (run time) for each model
 * The number of times to execute each model (with the inputs to the models 
 for each evaluation)
 * Number of processors to run on

**Determine**

A strategy for spreading the executions of all models across the processors 
such that all processors have a similar amount of work to do (minimize idle 
time for processors)

#### Implementation

Develop an engine function with an interface that accepts a list of `UQmodel` 
objects and a list of `numpy` arrays defining the inputs for each model,

<img src="/imgs/inputs.png" width="600">

note that in general the individual numpy arrays will have different lengths
(number of inputs). This function returns a list of numpy arrays defining
the outputs

<img src="/imgs/outputs.png" width="600">

where each array has been generated by evaluating the appropriate `UQmodel`,
for example: 

<img src="/imgs/run_model.png" width="600">

assuming that `model-1` has `N1` inputs to evaluate. 

If the approximate cost of each model is `C1`, ..., `CM`, then the total time 
to run all of the models on one processor is `T-serial = N1 * C1 + N2 * C2 + ... NM * CM`. 
The specific goal is to write an engine function that has an execution time that 
is as close to `T-parallel = T1 / P` as possible when run on `P` processors. An example of 
a serial engine function can be seen in the `tests/engine_check.py` in the 
`simple_serial_engine` function. 

The implementation of the engine is completely open; however, a solution that 
works in a distributed memory system is preferred. `mpi4py` is one example of a 
distributed processing tool that could be helpful, though others exist as well.

A script for checking implementations of the engine is included in the miniapp: 
`tests/engine_check.py`. The script runs the engine, checks its outputs, and 
computes its efficiency.  The script is configurable to test many different 
possibilities of model number, run times, etc.  Note that it is likely that the 
script will need to be modified to work in the context of the engine you 
develop.  It should prove useful, nonetheless.
